{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical testing\n",
    "# Ronald A. Fisher coined the Lady Tasting Tea Problem\n",
    "# The lady can ascertain whether tea had milk first or second during preparation phase\n",
    "# How many combinations of arrangements can the lady make from 8 cups of tea?\n",
    "cups = list(range(8))\n",
    "cups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we or the lady were to select cups randomly, 1 of 70 options are possible.\n",
    "# 1 of 70 from: (8*7*6*5)/(4*3*2*1) = 70\n",
    "\n",
    "# We will use the itertools package from Python\n",
    "# All possibilities/combinations are generated\n",
    "import itertools\n",
    "\n",
    "cups = list(range(8))\n",
    "poss = list(itertools.combinations(cups, 4))\n",
    "poss\n",
    "\n",
    "# This takes the list(cups) along with a number(4)\n",
    "# This returns every possible way of selecting 4 random cups from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Hypothesis\n",
    "# Null hypothesis is defined as the test subject unable to tell if the cup had milk first or second.\n",
    "\n",
    "# Alternative Hypothesis\n",
    "# If the test subject can choose the 4 cups with milk correctly,\n",
    "# there is a 1 in 70 chance of this happening or approx 1.4%.\n",
    "\n",
    "(1/70)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1:\n",
    "# The code above gives about a 1.5% chance of randomly selecting the correct cups with milk first.\n",
    "# Calculate the minimum number of cups of tea required to ensure the\n",
    "# probability of randomly selecting the correct cups of tea is less than or equal to 1%\n",
    "\n",
    "# Bonus: How many would be required if you were to allow the taster to get one cup wrong whilst maintaining the 1% threshold?\n",
    "\n",
    "import itertools\n",
    "\n",
    "cups = list(range(100))\n",
    "poss = list(itertools.combinations(cups, 2))\n",
    "\n",
    "\n",
    "print(poss)\n",
    "\n",
    "(1/6)*100\n",
    "\n",
    "# 1 of 6 from: (4*3)/(2*1) = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "import random\n",
    "import seaborn\n",
    "\n",
    "milkfirst = set(random.choice(poss))\n",
    "\n",
    "counts = [len(milkfirst & set(i)) for i in itertools.combinations(cups, 4)]\n",
    "\n",
    "seaborn.countplot(x = counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Use scipy's version of Fisher's exact test to simulate the Lady Tasting Tea problem\n",
    "\n",
    "# https://www.statology.org/fishers-exact-test-python/\n",
    "# Fisher's Exact Test is used to examine whether or not there is a major association between two variables.\n",
    "\n",
    "# Research on reference link TBC soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-tests & simulated data\n",
    "# Fake data sets can be created with specific properties to investigate numerical methods\n",
    "\n",
    "# Parameters for two different lists of numbers\n",
    "m_a, s_a, m_b, s_b = 1.0, 0.4, 2.0, 0.4\n",
    "# Sample size\n",
    "N = 40\n",
    "\n",
    "# Creating two lists of numbers based on bell-shaped probability curves\n",
    "a = np.random.normal(loc = m_a, scale = s_a, size = N)\n",
    "b = np.random.normal(loc = m_b, scale = s_b, size = N)\n",
    "\n",
    "# Placing both samples into one data frame\n",
    "df = pd.DataFrame({'Category': ['A'] * len(a) + ['B'] * len(b), 'Value': np.hstack([a, b])})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing various useful packages for Python\n",
    "# Efficient numerical arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Data frames.\n",
    "import pandas as pd\n",
    "\n",
    "# Alternative statistics package.\n",
    "import statsmodels.stats.weightstats as stat\n",
    "\n",
    "# Mains statistics package.\n",
    "import scipy.stats as ss\n",
    "\n",
    "# Plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fancier plotting.\n",
    "import seaborn as sns\n",
    "\n",
    "# Better sized plots.\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Nicer colours and styles for plots.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Visualising data\n",
    "sns.catplot(x = 'Category', y = 'Value', jitter = False, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running T-test via scipy.stats\n",
    "import scipy.stats as ss\n",
    "\n",
    "t_ss, p_ss = ss.ttest_ind(a, b)\n",
    "print(f\"t-value: {t_ss}\\tp-value: {p_ss}\")\n",
    "print(f\"P_scipy: {p_ss: 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running T-test via statsmodels\n",
    "\n",
    "t_sm, p_sm, d_sm = stat.ttest_ind(a, b)\n",
    "print(f\"t-value: {t_sm}\\tp-value: {p_sm}\\tDeg Free: {d_sm}\")\n",
    "print(f\"P_statsmodels: {p_sm: 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating t statistic \"by hand\"\n",
    "# https://en.wikipedia.org/wiki/Test_statistic\n",
    "\n",
    "# Length of the arrays\n",
    "n1 = len(a)\n",
    "n2 = len(b)\n",
    "\n",
    "# Means of the samples\n",
    "m1 = np.sum(a) / n1\n",
    "m2 = np.sum(b) / n2\n",
    "\n",
    "# Sample standard deviations\n",
    "s1 = np.sqrt(np.sum((a - m1) ** 2) / (n1 - 1))\n",
    "s2 = np.sqrt(np.sum((b - m2) ** 2) / (n2 - 1))\n",
    "\n",
    "df = n1 + n2 - 2\n",
    "sp2 = ((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / df\n",
    "t = (m1 - m2) / (np.sqrt(sp2) * np.sqrt(1.0/n1 + 1.0/n2))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populations\n",
    "# Setting x values\n",
    "\n",
    "min_x = min(m_a, m_b) - 5.0 * max(s_a, s_b)\n",
    "max_x = max(m_a, m_b) + 5.0 * max(s_a, s_b)\n",
    "x = np.linspace(min_x, max_x, 1000)\n",
    "\n",
    "# Normal distribution plots of two different populations\n",
    "# https://en.wikipedia.org/wiki/Normal_distribution\n",
    "\n",
    "y_a = ss.norm.pdf(x, m_a, s_a)\n",
    "y_b = ss.norm.pdf(x, m_b, s_b)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "ax.plot(x, y_a)\n",
    "ax.plot(x, y_b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical Value: used to make a decision in relation to the calculated t statistic from samples\n",
    "\n",
    "# The critical probability value\n",
    "critical = 0.05\n",
    "\n",
    "# Creating the figure\n",
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "# Range of x values, which represent the t statistic\n",
    "min_x = -5.0\n",
    "max_x = 5.0\n",
    "x = np.linspace(min_x, max_x, 1000)\n",
    "\n",
    "# The probability density function of the t statistic\n",
    "# Using the degrees of freedom listed above and plotting figure\n",
    "t = ss.t.pdf(x, d_sm)\n",
    "\n",
    "ax.plot(x, t, color = 'red')\n",
    "\n",
    "# Getting the tails & plotting them\n",
    "tf = pd.DataFrame({'x': x, 't': t})\n",
    "tcrit = abs(ss.t.ppf(critical / 2.0, d_sm))\n",
    "tail_one = tf[tf['x'] >= tcrit]\n",
    "tail_two = tf[tf['x'] <= -tcrit]\n",
    "\n",
    "ax.fill_between(tail_one['x'], tail_one['t'], 0, facecolor = \"red\")\n",
    "ax.fill_between(tail_two['x'], tail_two['t'], 0, facecolor = \"red\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type I Errors: False Positives\n",
    "# Running 10,000 t-tests where the population means are equal\n",
    "# We should make the wrong decision (reject the hypothesis) (100 * critical) percent of the time\n",
    "\n",
    "# Setting number of t-tests to run\n",
    "trials = 10000\n",
    "# Setting number of values per sample\n",
    "N = 100\n",
    "# Population 1 mean, Population 2 mean, Standard Deviation in both\n",
    "mean1, mean2, stddev = 2.0, 2.0, 0.3\n",
    "# Critical probability value\n",
    "critical = 0.05\n",
    "\n",
    "# Running total of type I errors committed\n",
    "rejects = 0\n",
    "\n",
    "# Looping through the t-tests\n",
    "for i in range(trials):\n",
    "    # Generating Sample 1\n",
    "    sample1 = np.random.normal(loc = mean1, scale = stddev, size = N)\n",
    "    # Generating Sample 2\n",
    "    sample2 = np.random.normal(loc = mean2, scale = stddev, size = N)\n",
    "    # Running t-test\n",
    "    t, p = ss.ttest_ind(sample1, sample2)\n",
    "    # If p is less than or equal to critical, reject it\n",
    "    if p <= critical:\n",
    "        rejects = rejects + 1\n",
    "\n",
    "# Printing results\n",
    "typei = 100.0 * (rejects / trials)\n",
    "print(f\"{typei: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type II Errors: False Negatives\n",
    "# Running 10,000 t-tests where the population means are not equal\n",
    "\n",
    "# Setting number of t-tests to run\n",
    "trials = 10000\n",
    "# Setting number of values per sample\n",
    "N = 100\n",
    "# Population 1 mean, Population 2 mean, Standard Deviation in both\n",
    "mean1, mean2, stddev = 2.0, 2.1, 0.3\n",
    "# Critical probability value\n",
    "critical = 0.05\n",
    "\n",
    "# Running total of type I errors committed\n",
    "notrejects = 0\n",
    "\n",
    "# Looping through the t-tests\n",
    "for i in range(trials):\n",
    "    # Generating Sample 1\n",
    "    sample1 = np.random.normal(loc = mean1, scale = stddev, size = N)\n",
    "    # Generating Sample 2\n",
    "    sample2 = np.random.normal(loc = mean2, scale = stddev, size = N)\n",
    "    # Running t-test\n",
    "    t, p = ss.ttest_ind(sample1, sample2)\n",
    "    # If p is greater than critical, do not reject it\n",
    "    if p > critical:\n",
    "        notrejects = notrejects + 1\n",
    "\n",
    "# Printing results\n",
    "typeii = 100.0 * (notrejects / trials)\n",
    "print(f\"{typeii: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired Samples\n",
    "# Vincent Arel-Bundock's R datasets list\n",
    "dfsleep = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/sleep.csv\")\n",
    "dfsleep\n",
    "\n",
    "# Extracting first sample from the data set\n",
    "drugA = dfsleep[dfsleep[\"group\"] == 1]\n",
    "drugA = drugA.sort_values(\"ID\")\n",
    "drugA = drugA[\"extra\"].to_numpy()\n",
    "drugA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting second sample from the data set\n",
    "drugB = dfsleep[dfsleep[\"group\"] == 2]\n",
    "drugB = drugB.sort_values(\"ID\")\n",
    "drugB = drugB[\"extra\"].to_numpy()\n",
    "drugB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a paired samples t-test\n",
    "ss.ttest_rel(drugA, drugB)\n",
    "\n",
    "# Equivalent to a one sample t-test\n",
    "ss.ttest_1samp(drugB - drugA, 0)\n",
    "\n",
    "# Suggestion from statsmodels for running the t-test\n",
    "stat.DescrStatsW(drugB - drugA).ttest_mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problems with multiple t-tests\n",
    "# If we want to compare three groups, and null hypothesis is all population means are equal.\n",
    "# Can three t-tests run in parallel?\n",
    "\n",
    "# Size of each sample\n",
    "N = 100\n",
    "\n",
    "# Creating three samples\n",
    "sampA = np.random.normal(1.0, 0.2, N)\n",
    "sampB = np.random.normal(1.0, 0.2, N)\n",
    "sampC = np.random.normal(2.0, 0.2, N)\n",
    "\n",
    "# Put samples in a single data frame\n",
    "sample = ['A'] * N + ['B'] * N + ['C'] * N\n",
    "values = np.hstack([sampA, sampB, sampC])\n",
    "dfsamps = pd.DataFrame({'Sample': sample, 'Value': values})\n",
    "\n",
    "# Visualising samples\n",
    "sns.catplot(x = 'Sample', y = 'Value', jitter = False, data = dfsamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-tests for each pair\n",
    "t_AB, p_AB = ss.ttest_ind(sampA, sampB)\n",
    "t_AC, p_AC = ss.ttest_ind(sampA, sampC)\n",
    "t_BC, p_BC = ss.ttest_ind(sampB, sampC)\n",
    "print(f\"p_AB: {p_AB: .2f}\\tp_AC: {p_AC: .2f}\\tp_BC: {p_BC: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running 10,000 t-tests where the population means are equal\n",
    "# We should make the wrong decision (reject the hypothesis) (100 * critical) percent of the time\n",
    "# We expect to incorrectly reject the null hypothesis 5% of the time\n",
    "\n",
    "# Setting number of t-tests to run\n",
    "trials = 10000\n",
    "# Setting number of values per sample\n",
    "N = 100\n",
    "# Population 1 mean, Population 2 mean, Population 3 mean, Standard Deviation in both\n",
    "mean1, mean2, mean3, stddev = 2.0, 2.0, 2.0, 0.3\n",
    "# Critical probability value\n",
    "critical = 0.05\n",
    "\n",
    "# Running total of type I errors committed\n",
    "rejects = 0\n",
    "\n",
    "# Looping through the t-tests\n",
    "for i in range(trials):\n",
    "    # Generating Sample 1\n",
    "    sample1 = np.random.normal(loc = mean1, scale = stddev, size = N)\n",
    "    # Generating Sample 2\n",
    "    sample2 = np.random.normal(loc = mean2, scale = stddev, size = N)\n",
    "    # Generating Sample 3\n",
    "    sample3 = np.random.normal(loc = mean3, scale = stddev, size = N)\n",
    "    # Running t-tests\n",
    "    t1, p1 = ss.ttest_ind(sample1, sample2)\n",
    "    t2, p2 = ss.ttest_ind(sample1, sample3)\n",
    "    t3, p3 = ss.ttest_ind(sample2, sample3)\n",
    "    # If any are less than or equal to critical, reject them\n",
    "    if p1 <= critical or p2 <= critical or p3 <= critical:\n",
    "        rejects = rejects + 1\n",
    "\n",
    "# Printing results\n",
    "typei = 100.0 * (rejects / trials)\n",
    "print(f\"{typei: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Variance (ANOVA)\n",
    "# ANOVA may be used to avoid a higher Type I error rate: false positives\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html\n",
    "F, P = ss.f_oneway(sampA, sampB, sampC)\n",
    "print(f\"F: {F: .2f} P: {P: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running 10,000 ANOVAs where the population means are equal\n",
    "# We should make the wrong decision (reject the hypothesis) (100 * critical) percent of the time\n",
    "# We expect to incorrectly reject the null hypothesis 5% of the time\n",
    "\n",
    "# Setting number of t-tests to run\n",
    "trials = 10000\n",
    "# Setting number of values per sample\n",
    "N = 100\n",
    "# Population 1 mean, Population 2 mean, Population 3 mean, Standard Deviation in both\n",
    "mean1, mean2, mean3, stddev = 2.0, 2.0, 2.0, 0.3\n",
    "# Critical probability value\n",
    "critical = 0.05\n",
    "\n",
    "# Running total of type I errors committed\n",
    "rejects = 0\n",
    "\n",
    "# Looping through the t-tests\n",
    "for i in range(trials):\n",
    "    # Generating Sample 1\n",
    "    sample1 = np.random.normal(loc = mean1, scale = stddev, size = N)\n",
    "    # Generating Sample 2\n",
    "    sample2 = np.random.normal(loc = mean2, scale = stddev, size = N)\n",
    "    # Generating Sample 3\n",
    "    sample3 = np.random.normal(loc = mean3, scale = stddev, size = N)\n",
    "    # Running ANOVA test\n",
    "    F, p = ss.f_oneway(sample1, sample2, sample3)\n",
    "    # If less than or equal to critical, reject it\n",
    "    if p <= critical:\n",
    "        rejects = rejects + 1\n",
    "\n",
    "# Printing results\n",
    "typei = 100.0 * (rejects / trials)\n",
    "print(f\"{typei: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "# Take the code from the Examples section of the scipy stats\n",
    "# documentation for independent samples t-tests,\n",
    "# add it to your own notebook and explain how it works\n",
    "# using MarkDown cells and code comments.\n",
    "# Improve it in any way you think it could be improved.\n",
    "\n",
    "# Research TBC\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f82d0fd1be96d5c2cfc8b5b6d623de297a3323bdcee05967133f841892dc18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
